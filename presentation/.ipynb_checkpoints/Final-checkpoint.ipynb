{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LargeVis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dataFlow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing K-nearest neighbor graph\n",
    "1. Random projection trees used to approximate the KNN graph\n",
    "2. Algorithm starts by partitioning the entire space and building up a tree\n",
    "3. For every non-leaf node of the tree, the algorithm selects a random hyperplane to split the subspace corresponding to the non-leaf node into two, which become the children of that node\n",
    "4. This process continues until the number of nodes in the subspace reaches a threshold\n",
    "5. Once a random projection tree is constructed, every data point can traverse the tree to find a corresponding leaf node. The points in the subspace of that leaf node will be treated as the candidates of the nearest neighbors of the input data point.\n",
    "6. In practice multiple trees can be built to improve the accuracy of the nearest neighbors.\n",
    "7. Once the nearest neighbors of all the data points are found, the K-nearest neighbor graph is built.\n",
    "\n",
    "### Constructing a very accurate KNN graph requires many trees to be built, which significantly hurts the efficiency\n",
    "\n",
    "Instead of building a large number of trees to obtain a highly accurate KNN graph, we use neighbor exploring techniques to improve the accuracy of a less accurate graph. The basic idea is that “a neighbor of my neighbor is also likely to be my neighbor”\n",
    "\n",
    "For each node of the graph, we search the neighbors of its neighbors, which are also likely to be candidates of its nearest neighbors. We may repeat this for multiple iterations to improve the accuracy of the graph. In practice, we find that only a few iterations are sufficient\n",
    "to improve the accuracy of the KNN graph to almost 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection into 2D/3D\n",
    "**principled probabilistic model** - idea is to preserve the similarities of the vertices in the low-dimension, we want to keep similar vertices close to each other and dissimilar vertices far apart in the low-dimensional space.\n",
    "\n",
    "Directly maximizing cost function is computationally expensive - ***randomly sample*** some negative edges for model optimization\n",
    "\n",
    "***Asynchronous stochastic gradient descent*** for optimalization\n",
    "\n",
    "Time complexity - ***linear*** to numbber of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 Neighbours\n",
    "<img src=\"LArgeViz302D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90 Neighbours\n",
    "<img src=\"LargeViz902D.png\">\n",
    "<img src=\"LargeViz903D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 150 Neighbours\n",
    "<img src=\"LargeViz1502D.png\">\n",
    "<img src=\"LargeViz1503D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 300 Neighbours\n",
    "<img src=\"LargeViz3002D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1200 Neighbours\n",
    "<img src=\"LargeViz12002D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to t-SNE\n",
    "* Significantly ***reduces the computational cost*** of the graph construction step\n",
    "* Employs a principled probabilistic model for the visualization step , the objective of which can be effectively optimized through asynchronous stochastic gradient descent with a ***linear time complexity***.\n",
    "\n",
    "* The whole procedure thus easily ***scales*** to millions of highdimensional data points.\n",
    "\n",
    "* Experimental results on real-world data sets demonstrate that the LargeVis ***outperforms*** the state-of-the-art methods in both efficiency and effectiveness.\n",
    "\n",
    "* The hyper-parameters of LargeVis are also much more ***stable*** over different data sets.\n",
    "\n",
    "<img src=\"comparision.png\">\n",
    "<img src=\"compare.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE\n",
    "<img src=\"tsne7000.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
